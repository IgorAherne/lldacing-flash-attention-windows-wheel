# lldacing-flash-attention-windows-wheel

(not mine) repository to hold [windows wheels BY LLDACING](https://huggingface.co/lldacing/flash-attention-windows-wheel/tree/main)

Supports:
- Python 3.10, 3.11, 3.12
- Cuda 12.4, 12.6 
- Pytorch 2.4, 2.4.1, 2.5, 2.5.1, 2.6

original license on huggingface: BSD-3-Clause

files: https://github.com/IgorAherne/lldacing-flash-attention-windows-wheel/releases/tag/latest
